[
  {
    "objectID": "ways_of_working.html",
    "href": "ways_of_working.html",
    "title": "Ways of working",
    "section": "",
    "text": "Note\n\n\n\nThis is a draft and is published for feedback purposes. The contents of these pages may change in future in response to feedback and suggestions."
  },
  {
    "objectID": "ways_of_working.html#motivation",
    "href": "ways_of_working.html#motivation",
    "title": "Ways of working",
    "section": "Motivation",
    "text": "Motivation\nThese ways of working make RAP easier to implement and more productive. While coding standards are important, it’s just as important to manage your analysis code in the right way."
  },
  {
    "objectID": "ways_of_working.html#code-modules-should-run-end-to-end-without-manual-intervention",
    "href": "ways_of_working.html#code-modules-should-run-end-to-end-without-manual-intervention",
    "title": "Ways of working",
    "section": "6. Code modules should run end to end without manual intervention",
    "text": "6. Code modules should run end to end without manual intervention\nYou should not have to make manual changes to the code or modify parameters during execution. Pipeline scripts should run from end to end. This doesn’t mean automating everything! Rather, think about how best to break the workflow down into sensible steps. If you have manual QA checks to perform, you can do those after the pipeline has finished by building the checks into the run and saving run logs and QA outputs for review.\n\n6.1 Minimise manual steps\nAutomation isn’t just about efficiency. Automating manual steps reduces the risk of error. While those steps might be easy to carry out, each manual step introduces the risk of human error. Automate analysis steps that computers can do more reliably than us, such as performing basic checks, generating standard quality reports and saving outputs.\n\n\n6.2 Use configuration files\nAnalysts often write pipelines that need frequent adjustment, sometimes even while running the pipeline.\nFor example, we often see scripts where variables need updating or code must be commented in and out (effectively adding or removing code chunks during execution). Sometimes comments are even used to record when changes were made.\nWorking in this way is bad for reproducibility because:\n\nIt is very hard to see what the code looked like for each pipeline run.\n\nIt makes the process hard to document, as the analyst needs to know which parts of it to change and when.\n\nIt makes it hard to version control, because it is not clear who made which changes, when and why.\n\nUse configuration to handle these changes outside of the pipeline itself.\nConfiguration files store settings for your pipeline. For example, if you know you might need to manually change the input file name, it makes sense for it to be loaded in from the configuration file, so you don’t have to change every time it appears in your script.\nThe file also acts as documentation, because it allows others to see which settings were used to run the code, without needing to read the entire code base. Other configuration settings might be things like dates, data and output folder locations, geographical areas, and model parameters.\n\n\n\n\n\n\nTip\n\n\n\nConfiguration files are especially useful for re-usable pipelines, like regular publications. However, they are also useful for one-off pieces work.\nUsing a configuration file from the start makes code development easier if your code needs a lot of set up. For example, you might need to frequently change parameters when developing a model, even if the resulting model will be a single-use piece of work."
  },
  {
    "objectID": "ways_of_working.html#use-git-for-version-control",
    "href": "ways_of_working.html#use-git-for-version-control",
    "title": "Ways of working",
    "section": "7. Use git for version control",
    "text": "7. Use git for version control\nVersion control is about managing changes to your analysis over time. Using git for version control means you can see what previous versions of the code looked like and even revert to previous iterations of your pipeline, which is very difficult to do manually.\nIf used correctly, git will help you keep an audit trail of who made which contributions, when and why. This also improves efficiency by helping you to collaborate and track changes more effectively.\nAvoid archiving code in your repository or commenting out blocks of code that you no longer use. Using git means you can delete code that you don’t need anymore because it is preserved in the version history. Your repository should not need to contain archived folders or commented out code."
  },
  {
    "objectID": "ways_of_working.html#make-sure-your-code-meets-quality-standards",
    "href": "ways_of_working.html#make-sure-your-code-meets-quality-standards",
    "title": "Ways of working",
    "section": "8. Make sure your code meets quality standards",
    "text": "8. Make sure your code meets quality standards\nUltimately, the aim of RAP is to produce high quality statistical outputs. When thinking about the quality of your code you should consider how the ways you work help you to achieve this. This means making sure code quality is proportionate to how complex and risky your pipeline is. Below are the essential quality assurance practices for analysis code. Remember that complex, high risk projects may require extra forms of quality assurance.\n\n8.1 Make sure your analysis meets quality standards\nAnalysis carried out using code should meet the same quality standards as any other analysis. That means using the principles and practices set out in the [AQuA Book]https://www.gov.uk/government/publications/the-aqua-book-guidance-on-producing-quality-analysis-for-government) and the ONS quality standard for analysis.\n\n\n8.2 Review all code as you go\nAim to review your entire code base at least once. Do this as you develop the code rather than at the end. If possible, code should be reviewed during development by someone who didn’t write it. Consider the quality of the code as well as whether it’s doing what it’s supposed to. Use code reviews to make sure your code is readable, reproducible and well documented as well as whether it works. The code review ONS Wiki template provides a set of criteria for code review.\n\n\n8.3 Test your code\nTest your code to make sure it does what you expected it to. Just because code runs without errors and produces outputs that look plausible does not guarantee that it works as intended!\nThere are many ways to test code. Usually, testing is a lot easier when your code is modular or packaged. Make sure your tests are proportionate to risks and complexity. Ideally, tests should be formalised, whether they are manual or automated.\n\n\n\n\n\n\nTip\n\n\n\nAutomating tests makes it much easier to document exactly how you tested your code and makes your tests easier to re-run.\nWays to test code include:\n\nUnit tests: automated testing of each function against expected outcomes\n\nIntegration tests: tests of how different functions work together\n\nParallel runs: running a new pipeline and comparing results with those of the existing pipeline\n\nRunning the code on different systems to ensure it produces a reliable outcome\n\n\n\nTests are not a tick box exercise! Each test should serve a clear purpose. Good tests will help you spot issues with the code before errors happen and speed up code production."
  },
  {
    "objectID": "ways_of_working.html#maintain-and-improve-your-code-continuously-applies-to-re-usable-code",
    "href": "ways_of_working.html#maintain-and-improve-your-code-continuously-applies-to-re-usable-code",
    "title": "Ways of working",
    "section": "9 Maintain and improve your code continuously (applies to re-usable code)",
    "text": "9 Maintain and improve your code continuously (applies to re-usable code)\nCode that is intended for re-use is never truly “finished”. You should expect to continue to maintain the code for as long as it needs to be used. Things like changes to your input data or the systems you use might require unexpected code changes.\n\n9.1 Make code improvements before errors occur\nCode is much harder to fix once an error has already occurred. Locating the source of the error and fixing the issue is much harder under pressure. Instead, you can focus on reducing risks in the code before they cause any errors. This migth mean making the code easier to change in future, doing more quality assurance and testing, or coding solutions for issues that are likely to arise in future, even if they haven’t happened before. Aim to improve your code even while it is functioning correctly to avoid future mistakes.\n\n\n9.2 Develop your code iteratively\nDon’t expect to develop everything to the highest standard right away. If your team are still learning to implement RAP you might aim for a basic set of code at first and improve on it over time. Be aware, however, that lower quality code will need more work in future compared with code that is well written, modular, documented and tested. Early code might also not fully meet user needs. You may want to initially prioritise the most important functionality and later add additional functionality/\n\n\n10 avoid reinventing the wheel the wheel (highly recommended)\nOpen source code is a great tool when it comes to building pipeline. There are usually solutions out there for common analysis problems that mean you don’t need to write everything from scratch. When tacking a new problem, it’s worth considering whether a package already exists that can help. We recommend using packages that are well established and actively maintained, which you can find out by visiting their github repositories or equivalents.\nThere are many resources online that can help you if such a package isn’t available. Forums like Stack Overflow carry solutions to common errors or bugs and users often offer code examples."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Note\n\n\n\nPlease note, this is a draft and is published for feedback purposes. The contents of these pages may change in response to feedback and suggestions."
  },
  {
    "objectID": "index.html#aims",
    "href": "index.html#aims",
    "title": "Home",
    "section": "Aims",
    "text": "Aims\nThis document sets a minimum standard for Reproducible Analytical Pipelines (RAP) for analysts at the Office for National Statistics. RAP refers to the use of tools and practices borrowed from software engineering to make our analysis more reproducible.\nAnalysis is reproducible if we can repeat the analysis process reliably. In practice, that means we can always produce the same outputs again given the same data. The “gold standard” for reproducibility is a pipeline that is robust and well documented enough that another analyst could reproduce your outputs with no support except your code, documentation, and data.\nThere is no single way to make analysis code reproducible. Rather, there are different ways of working that can help us get to that goal. We hope this document provides useful and coherent criteria for how a Reproducible Analytical Pipeline at ONS should look in practice.\nReproducibility is not an end in itself. Rather, it is necessary so our work has quality, value, and transparency. The minimum RAP standards are written with this in mind. The criteria set out in this document are there to make sure we get the most value out of reproducible analysis."
  },
  {
    "objectID": "index.html#how-should-the-standard-be-used",
    "href": "index.html#how-should-the-standard-be-used",
    "title": "Home",
    "section": "How should the standard be used?",
    "text": "How should the standard be used?\nThe standard sets a minimum set of expectations that code should comply with if it is used to produce analytical outputs. The analysis might be ad hoc, or it might be used to create official and national statistics or underpin other ONS analysis.\nWhile this is a minimum standard, there are many other techniques, tools and practices that can improve your code and make it even more efficient and reproducible. Once you comply with the minimum standard, we hope you will build on it to make your work even more resilient.\nWe do not expect all coding projects to meet the standard immediately. If your work does not comply with the minimum standard, you should put in place coherent, prioritised and achievable plans for how you will achieve compliance with the standard in time.\nMost of the practices and activities here apply to both re-usable pipelines and ad hoc analysis. Criteria that only apply to re-usable pipelines are highlighted when they appear.\nLastly, this document is not intended to teach coding skills. To improve your coding capability you can read our guidance on good coding practices or use ONS internal training courses, in particular the RAP Learning Pathway on the ONS Learning Hub."
  },
  {
    "objectID": "index.html#accessibility-statement",
    "href": "index.html#accessibility-statement",
    "title": "Home",
    "section": "Accessibility statement",
    "text": "Accessibility statement\nThis accessibility statement applies to the RAP minimum standards resource. Please note that this does not include third-party content that is referenced from this site.\nThe website is managed by the Methodology and Quality division of the Office for National Statistics. We would like this guidance to be accessible for as many people as possible. This means that you should be able to:\n\nchange colours, contrast levels and fonts\nzoom in up to 300% without the text spilling off the screen\nnavigate most of the website using just a keyboard\nnavigate most of the website using speech recognition software\nlisten to most of the website using a screen reader (including the most recent versions of JAWS, NVDA and VoiceOver)\n\n\nFeedback and reporting accessibility problems\nWe’re always looking to improve the accessibility of our guidance. If you find any problems not listed on this page or think that we’re not meeting accessibility requirements, please contact us by email at gsshelp@statistics.gov.uk. Please also get in touch if you are unable to access any part of this guidance, or require the content in a different format.\nWe will consider your request and aim to get back to you within 5 working days.\n\n\nEnforcement procedure\nThe Equality and Human Rights Commission (EHRC) is responsible for enforcing the Public Sector Bodies (Websites and Mobile Applications) (No. 2) Accessibility Regulations 2018 (the ‘accessibility regulations’). If you’re not happy with how we respond to your complaint, you should contact the Equality Advisory and Support Service (EASS)."
  },
  {
    "objectID": "index.html#contact-details",
    "href": "index.html#contact-details",
    "title": "Home",
    "section": "Contact details",
    "text": "Contact details\nWe would like to know what you think of the RAP minimum standard. Please contact us if you have feedback on any of the following:\n\nHow we might make the guidance clearer and easier to follow\nInformation you would like to see collected in the next iteration of the guidance\nAny other comments\n\nTo give feedback, please contact ASAP@ONS.gov.uk."
  },
  {
    "objectID": "code_standards.html",
    "href": "code_standards.html",
    "title": "Code standards",
    "section": "",
    "text": "Note\n\n\n\nThis guidance is a draft and is published for feedback purposes. The contents of these pages may change in future in response to user feedback."
  },
  {
    "objectID": "code_standards.html#motivation",
    "href": "code_standards.html#motivation",
    "title": "Code standards",
    "section": "Motivation",
    "text": "Motivation\nWell written code is easy to read and understand. As a result, it is also easy to amend, reuse and review. The actions below help to make your code more readable and easier to edit and maintain."
  },
  {
    "objectID": "code_standards.html#use-open-source-languages-and-tools",
    "href": "code_standards.html#use-open-source-languages-and-tools",
    "title": "Code standards",
    "section": "1. Use open-source languages and tools",
    "text": "1. Use open-source languages and tools\nWe recommend using open-source tools for your coding work. The Central Digital and Data Office (CDDO) Service Manual recommends an “open source by default” approach for government code. Open source languages and tools make work more accessible for users, colleagues and stakeholders. They can access and use them without expensive licenses. Using open source also makes it easier to on-board people, get external review and collaborate across teams and departments.\nTools must be appropriate for the problem you are trying to solve. Python and R are usually best for analysis workflows. They are our approved coding languages for analysis at ONS. Using R or Python will allow you to comply with this minimum standard. While you can use SQL in your code, a pipeline written entirely in SQL would not meet the standard.\nOpen-source languages also give you easy access to code packages created by others. There are large ecosystems of R and python packages designed for data science and statistics that can help you manipulate, analyse, and visualise data.\nUse standard, well tested packages in your code whenever you can, rather than reinventing the wheel. This saves time and increases resilience. Established packages with a large user base are usually extensively tested and have already had a lot of development work put into them.\nThe ONS Learning Hub includes extensive resources to help you improve your coding skills, including modules on the topics we cover here."
  },
  {
    "objectID": "code_standards.html#minimise-repetition",
    "href": "code_standards.html#minimise-repetition",
    "title": "Code standards",
    "section": "2. Minimise repetition",
    "text": "2. Minimise repetition\nRepetitive code is hard to read. It also makes errors and mistakes more likely. When the same logic repeats in multiple places you will have to change every single one of them when you update the pipeline. It is very easy to miss something, as the number of parameters you need to review and change soon mounts up.\nRepetitive code is inefficient to write and document. This also makes it harder to review your work. In extreme cases, complex and highly repetitive code can be so difficult to understand and maintain that it has to be abandoned and rewritten completely. Although highly repetitive code can still be reproducible and quality assured, we strongly recommend that you minimise repetition whenever you can in all of your code.\nSo how can you minimise repetition?\n\n2.1 Use control flow\nControl flow means changing the order that code runs in depending on the circumstances. This helps when you need to change and re-run your code often to adapt to different needs. Control flow uses two main tools: choices and loops. For example, you can use if statements to make the same code behave differently in different situations. You can use loops to execute the same chunk of code a number of times or until a certain condition is met. [link to relevant course]\n\n\n2.2 Use functions\nFunctions are chunks of self-contained code that can be called from anywhere. Once you’ve written a function, you can execute it as many times as you need to by calling its name rather than copying the code it runs into your main pipeline lots of times. Functions can be written to receive different information each time, so you can apply them in different situations. For example, you can write a function to calculate a mean average that will work on any set of numbers.\n\n\n2.3 Make complex code modular\nCode is modular when it is broken down into multiple, self-contained pieces. This makes the code easier to read, test and change. The best way to make code modular is to write most of your pipeline using functions or classes. Split long scripts into multiple modules, but make sure that you can still run the entire pipeline from one script or a single command. This is essential for code that is complex or intended for re-use, as larger code bases can quickly become difficult to manage."
  },
  {
    "objectID": "code_standards.html#make-your-code-readable-and-self-documenting",
    "href": "code_standards.html#make-your-code-readable-and-self-documenting",
    "title": "Code standards",
    "section": "3. Make your code readable and self-documenting",
    "text": "3. Make your code readable and self-documenting\nWell written code also needs less documentation. There are things you can do to make it much easier for an experienced programmer to pick up your code and use it without your help. Again, less readable code can still be reproducible, but writing more readable code will make your work more efficient and your code simpler and easier to review.\n\n\n\n\n\n\nTip\n\n\n\n“Don’t comment bad code. Re-write it.” - Brian W. Kernighan and P.J. Plaugher.\n\n\nUse comments to explain why your code is written the way it is, not what it does. It should be obvious what the code does just by reading it. If it isn’t, re-write it. The practices below will make your code easier to read and understand and reduce the need for lots of comments. Using easy-to-understand variable names, clear referencing of modules and libraries and modular, function-based code are excellent ways to reduce the need for lots of code comments.\n\n3.1 Use a standard code style\nWe recommend using PEP8 for python and the tidyverse or Google R Style Guide for R. These styles are designed to be readable and intuitive and experienced coders are familiar with them. If needed, you may want to adapt them a little for your local situation. While full compliance with well-established styles will maximise transparency, the main objective is to make sure everyone in your team agrees on and uses the same coding style.\n\n\n3.2 Everything that has a name in your code should have a name that is easy to understand\nThis includes things like variables, functions, modules, tests, scripts, and folders. Names should not be cryptic or obvious only to the people currently working on the code. The ONS Learning Hub courses on clean code for R and clean code for python are useful resources.\n\n\n3.3 It should be easy to understand which packages you use and where functions come from\nIn python, importing packages should be done at the top of the script.\nIn R, avoid loading whole libraries using library(). Instead, clearly reference the libraries you use in the code using R namespaces for any functions that are not included in base R.\n\n\n\n\n\n\nTip\n\n\n\nNamespaces make it clear exactly which library a function is from. For example, write ggplot2::ggplot() and dplyr::filter(), not just ggplot() and filter(). This makes it clear that when you are calling ggplot, you are calling the ggplot function from the ggplot2 library, not some other ggplot. If you don’t do this, you risk R loading the wrong function from the wrong library, and readers of your code will have no idea which library you meant to use.\n\n\nMake sure your documentation explains clearly which packages (in which versions) must be installed to run your code. The easiest and most robust way to do this is to build an R package. R packages set out your dependencies in a standard way as part of the specification. The digital books Advanced R and R Packages are excellent resources for R users who want to improve their coding skills."
  },
  {
    "objectID": "documentation.html",
    "href": "documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "Note\n\n\n\nThis is a draft and is published for feedback purposes. The contents of these pages may change in future in response to feedback and suggestions."
  },
  {
    "objectID": "documentation.html#motivation",
    "href": "documentation.html#motivation",
    "title": "Documentation",
    "section": "Motivation",
    "text": "Motivation\nEven well written code requires some documentation. Good documentation makes your code easier for someone else to understand and easier to work with. It also helps people who join the project or review the code. Documentation should always be up to date and stored alongside the code itself (for example as part of the code Gitlab or Github repository), so that people don’t have to search for it.\nDocumentation can also be excessive! Writing readable, automated code (see code standards) reduces the need for lots of code comments and lengthy desk instructions."
  },
  {
    "objectID": "documentation.html#document-everything-that-is-needed-to-write-and-run-the-code",
    "href": "documentation.html#document-everything-that-is-needed-to-write-and-run-the-code",
    "title": "Documentation",
    "section": "4. Document everything that is needed to write and run the code",
    "text": "4. Document everything that is needed to write and run the code\nYou should document everything that a contributor would need to know to review, edit or run your code. Things should be documented alongside the code whenever possible, rather than somewhere else that readers will need to find and search for. We have listed some essential forms of documentation below. You may need to make others, depending on the project.\n\n4.1 Create README files for every project\nAll pipelines should have a README file. README files are easy to create and maintain but are often neglected as part of pipeline development.\nThe README file should be the first thing that someone looking at your code reads. As a minimum, a README should include: * Background - what the code is for and the process it executes. * Set up instructions, for example how to install the code, get all the supporting packages you need, prepare your input data, and configure the workflow. * How to run the code.\nDepending on the project, you might add other information to your README file, such as how somebody can contribute to the code and which style guide to use. After reading the README, anyone should be able to install and run your code, provided they have access to the data.\nIf you need detailed running instructions, you might create an extra markdown file for these and link it to your README file.\n\n\n4.2 Embed design documentation with code\nEvery project should have some design documentation. How much you need depends on the complexity of the work. At the very least it should cover what the pipeline does, what it uses as its inputs and what outputs it makes. This can be included in the README file, or linked from it. You can also use flow charts to show what the overall design looks like. It is also useful to link to other documentation about the methods used and why the workflow is set up as it is.\nDocumenting the design helps everyone understand what the code is supposed to achieve. It also helps you to assess whether the code actually does what it is supposed to do. Having a clear idea of the overall design and why it is set up this way also makes it clear whether the code could be improved.\n\n\n4.3 Document dependencies\nMost pipelines rely on external packages. Make it as easy as possible for others to replicate the correct environment when running the code. That means documenting the packages you use, for example using requirements files in python or a DESCRIPTION file and other package documentation in R. Generally, packaging your code in python modules or an R package is the best way to make sure dependencies are handled cleanly.\nAt a minimum, you should have a list of dependencies. If you need specific versions of these for the code to work, make sure you let your users know which versions they can use.\n\n\n4.4 Record manual quality assurance and tests\nWhen tests and checks are not automated, record these alongside the code. Include manual checks and tests in desk instructions, for example in the README file or a separate testing guide. This means other people running the pipeline will be able to replicate your quality assurance steps and verify the work you have done.\nFor manual tests and checks, maintain a clear record of what was tested, who by, when and what they found. The easiest way to do this is as part of a code review, which you can record using pull requests on GitHub or merge requests on Gitlab."
  },
  {
    "objectID": "documentation.html#document-what-the-code-is-doing",
    "href": "documentation.html#document-what-the-code-is-doing",
    "title": "Documentation",
    "section": "5. Document what the code is doing",
    "text": "5. Document what the code is doing\nYour scripts should contain enough documentation for other coders to be able to understand what each part of the code is intended to do. However, there is such a thing as too much documentation. Documentation inside the code should not repeat things that are documented elsewhere, for example in the README file.\n\n5.1 Code comments should explain the “why” not the “how”\nUse code comments (other than function documentation) sparingly. Code comments are there to explain why the code is written the way it is when it would not be obvious to an experienced programmer. They are not there to explain the syntax to inexperienced programmers or to repeat in plain English the logic that is already there in the code.\n\n\n\n\n\n\nTip\n\n\n\nToo many code comments make code hard to read and work with!\nThe one exception to this rule is when the code is written specifically for learning purposes. A lot of people assume code should be littered with comments, as the tutorial code they learned from was heavily commented. If colleagues struggle to understand production code, you should support them to learn rather than turning pipeline code into tutorial code.\n\n\nExplanations of methodology or your catalogue of assumptions do not belong in code comments. Rather, you should record them elsewhere and signpost them in your documentation. For example, you can create assumption or methodology documentation files and place them alongside the code in your repository. It can be useful to note in your code comments when an assumption you have made applies directly, but you should reference the assumption and where it can be found, not set it out in detail in the code comments.\n\n\n5.2 Document functions and classes\nIf your code uses functions and classes, you must document them appropriately. In python that means using docstrings. In R it means using roxygen2. These formats are especially useful when packaging code in R or writing modules and packages in python. We recommend using them for all your functions and classes because they give you a standard format to work with that makes it much easier to package code at a later date. Otherwise, you can use a block of code comments.\nGood function and class documentation reduces the need to clutter the code with comments and ensures you cover the most important information. Always document what a function or class takes in as its inputs, what it does, and what output it produces. If you can, provide an example of use."
  },
  {
    "objectID": "project_management.html",
    "href": "project_management.html",
    "title": "Project management",
    "section": "",
    "text": "Note\n\n\n\nPlease note, this is a draft and is published for feedback purposes. The contents of these pages may change in future in response to feedback and suggestions."
  },
  {
    "objectID": "project_management.html#motivation",
    "href": "project_management.html#motivation",
    "title": "Project management",
    "section": "Motivation",
    "text": "Motivation\nGood project management is essential for making code sustainable and fit for purpose. This should not mean lots of additional meetings or box-ticking exercises! It is about making the right decisions at the right time to ensure coding work goes as smoothly as possible. You may already do some or all of what we set out here."
  },
  {
    "objectID": "project_management.html#set-out-clear-aims-and-scope-for-each-project",
    "href": "project_management.html#set-out-clear-aims-and-scope-for-each-project",
    "title": "Project management",
    "section": "10. Set out clear aims and scope for each project",
    "text": "10. Set out clear aims and scope for each project\nA project should have clear aims before you begin coding. Without them, you will not be able to set a proportionate level of quality assurance and decide how much documentation you will need for the work. Deciding on your aims early on will keep your project focused on the end goal.\nYou should also have a clear idea of what is and is not in scope for your coding project. It should be clear to everyone involved where your responsibilities begin and end. This will depend on factors like the number of business areas involved, the complexity of the pipeline and the IT systems you will use. Make sure that other people involved in the analysis know what is in and out of scope for the project to avoid scope creep, where you end up taking on more and more work that should not be part of the project."
  },
  {
    "objectID": "project_management.html#set-out-your-quality-specifications",
    "href": "project_management.html#set-out-your-quality-specifications",
    "title": "Project management",
    "section": "11. Set out your quality specifications",
    "text": "11. Set out your quality specifications\nIdeally, all analysis code should be of the highest possible standard. Realistically, quality should be proportionate to complexity and risk. Highly complex and impactful work will require more testing, review, and documentation than a simple pipeline with lower impact. The practices included here should be proportionate and sufficient for most official statistics work, but you may need to do more for mission-critical pipelines.\nQuality specifications should not be determined by the skill level in your team. Instead, aim to increase your team’s capability to meet appropriate quality levels based on the complexity and risk of your analysis."
  },
  {
    "objectID": "project_management.html#if-appropriate-plan-to-open-source-your-code-in-future",
    "href": "project_management.html#if-appropriate-plan-to-open-source-your-code-in-future",
    "title": "Project management",
    "section": "12. If appropriate, plan to open source your code in future",
    "text": "12. If appropriate, plan to open source your code in future\nThe Government Service Manual says that code funded by the public should be made open source unless there is a good reason not to do so. Plan coding projects with open source in mind, even if open sourcing the code will not be possible for a while. If you cannot open source your code in its current form, consider whether there are things you can do to make it safe to open source. There is Analysis Function guidance on how to open source code effectively and how to decide whether to open source analytical code."
  },
  {
    "objectID": "project_management.html#set-out-clear-well-defined-roles-and-responsibilities",
    "href": "project_management.html#set-out-clear-well-defined-roles-and-responsibilities",
    "title": "Project management",
    "section": "13. Set out clear, well-defined roles and responsibilities",
    "text": "13. Set out clear, well-defined roles and responsibilities\nEverybody on the project needs to know who is working on it and what their role is. This should be written down where everybody on the project can see it and updated as things change. People can have multiple roles and be responsible for multiple parts of the project. Recording roles and responsibilities early on and keeping them up to date means everybody knows who to turn to when important decisions need to be made or when something goes wrong. It also means you know when an important role is not covered and can manage the risk sensibly."
  },
  {
    "objectID": "project_management.html#make-a-succession-plan",
    "href": "project_management.html#make-a-succession-plan",
    "title": "Project management",
    "section": "14. Make a succession plan",
    "text": "14. Make a succession plan\nCode is not reproducible if only one person can understand and use it! Single points of failure mean serious risks to resilience and reproducibility. Readable and well documented code is already much easier for someone else to pick up, but you should be able to cope with losing one of the coders on your team. Plan to have two people working on the code at all times. If this is impossible, work out a clear plan to bring in more coding resource swiftly, either through recruitment or by borrowing resource from another team. Escalate these risks if you cannot resolve them."
  },
  {
    "objectID": "ways_of_working.html#use-version-control.-use-git-for-version-control",
    "href": "ways_of_working.html#use-version-control.-use-git-for-version-control",
    "title": "Ways of working",
    "section": "7. Use version control. Use git for version control",
    "text": "7. Use version control. Use git for version control\nUsing git for version control means you will be able to see what previous versions of the code looked like. That means you can revert to previous iterations of your pipeline, which is very difficult to do manually. If used correctly, git will help you keep an audit trail of who made which contributions, when and why. This also improves efficiency by helping you to collaborate and track changes more effectively.\nAvoid archiving code in your repository or commenting out blocks of code that you no longer use. Using git means you can delete code that you don’t need as it’s preserved in the version history. Your repository should not normally contain archive folders or commented out code."
  },
  {
    "objectID": "ways_of_working.html#maintain-and-improve-re-usable-code-continuously",
    "href": "ways_of_working.html#maintain-and-improve-re-usable-code-continuously",
    "title": "Ways of working",
    "section": "9 Maintain and improve re-usable code continuously",
    "text": "9 Maintain and improve re-usable code continuously\nCode that is intended for re-use is never truly “finished”. Expect to maintain the code for as long as it needs to be used. Things like changes to your input data or the systems you use might require unexpected code changes.\n\n9.1 Make code improvements before errors occur\nCode is much harder to fix once an error has already occurred. Finding the source of the error and fixing the issue is much harder under pressure.\nInstead, focus on reducing risks in the code before they cause errors. This might mean making the code easier to change in future, doing more quality assurance and testing, or coding solutions for issues that are likely to happen, even if they haven’t yet. Aim to improve your code while it is functioning correctly to avoid future mistakes.\n\n\n9.2 Develop your code iteratively\nDon’t expect to develop everything to the highest standard right away. If your team are still learning to implement RAP you might aim for a basic set of code at first and improve it over time. Early code might not fully meet user needs. You may want to prioritise the most important functionality first and add lower priority functionality later.\n\n\n\n\n\n\nCaution\n\n\n\nLower quality code usually needs more work in future compared with code that is well written, modular, documented and tested from the start.\n\n\n\n\n10 Avoid reinventing the wheel\nOpen source code is a great tool when it comes to building pipeline. There are usually already solutions out there for most common analysis problems that mean you don’t need to write everything from scratch.\nWhen tacking a new problem, check whether a package already exists that can help you. We recommend using packages that are well established and actively maintained, which you can find out by visiting their github repositories or equivalents.\nThere are many resources online that can help you if such a package isn’t available. Forums like Stack Overflow carry solutions to common errors or bugs and users often offer code examples."
  },
  {
    "objectID": "standard_at_a_glance.html",
    "href": "standard_at_a_glance.html",
    "title": "The ONS RAP standards at a glance",
    "section": "",
    "text": "Note\n\n\n\nThis is a draft and is published for feedback purposes. The contents of these pages may change in future in response to feedback and suggestions.\n\n\n\nUse open-source languages for coding\nMinimise repetition\n\nUse control flow\nUse functions\nMake complex code modular\n\nMake your code readable and self-documenting\n\nUse a standard code style\nEverything that has a name in your code should have a name that is easy to understand\nIt should be easy to understand which packages you use and where functions come from\n\nDocument everything that is needed to write and run the code\n\nCreate README files for every project\nEmbed design documentation with code\nDocument dependencies\nRecord manual quality assurance and tests\n\nDocument what the code is doing\n\nCode comments should explain the “why”, not the “how”\nDocument functions and classes\n\nCode modules should run end-to-end without manual intervention\n\nminimise manual steps\nUse configuration files\n\nUse git for version control\nMake sure your code meets quality standards\n\nMake sure your analysis meets quality standards\nReview all code as you go\nTest your code\n\nMaintain and improve re-usable code continuously\n\nMake code improvements before errors occur\nDevelop your code iteratively\n\nDon’t reinvent the wheel\nSet out clear aims and scope for each project\nSet out your quality specifications\nIf appropriate, plan to open source your code in the future\nSet out clear, well defined roles and responsibilities\nMake a succession plan"
  }
]